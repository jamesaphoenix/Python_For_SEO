{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. How To Combine Multiple CSV Files In Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "\n",
    "- To learn what the pd.concat() method is and how it works\n",
    "- Learn how to combine multiple csv files using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly let's say that we have 5, 10 or 100 .csv files. Combining all of these by hand can be incredibly tiring and definitely deserves to be automated. Therefore in today's exercise, we'll combine multiple csv files within only 8 lines of code.\n",
    "\n",
    "For this tutorial, I've already prepared 5 top pages .csv reports from Ahrefs which can be found in the following directory:\n",
    "\n",
    "~~~ \n",
    "\n",
    "data/pbpython.com-top-pages-by-traffic-subdomains-US-17-May-2020_20-24-30-2c4e06e2ea39cce8b2f514e24c929e51.csv\n",
    "data/machinelearningmastery.com-top-pages-by-traffic-subdomains-US-17-May-2020_20-25-38-b4088b6c6c987653748b10c0543a5713.csv\n",
    "\n",
    "~~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the problems with automatically detecting csv files is that <strong> the names are dynamically generated.</strong> Therefore we will be using the .csv file extension name and a python package called glob to automatically detect all of the files ending with a .csv name within a specific working directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and set the working directory\n",
    "\n",
    "You will need to change \"/directory\" to your <strong> specific directory. </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "# os.chdir(\"/directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By writing pwd within the command line, we can identify the exact file path that these top page .csv files are located in:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "\n",
    "pwd\n",
    "/Users/jamesphoenix/Desktop/Imran_And_James_Projects/Python_For_SEO/2_bulk_csv_operations/data\n",
    "\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/jamesphoenix/Desktop/Imran_And_James_Projects/Python_For_SEO/2_bulk_csv_operations/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly lets run the following two commands just to show that we have changed directory:\n",
    "\n",
    "~~~\n",
    "!ls \n",
    "!pwd\n",
    "\n",
    "~~~ \n",
    "\n",
    " <strong> Pro-tip: using ! before a linux command allows you to run the command within a jupyter notebook file!  </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jamesphoenix/Desktop/Imran_And_James_Projects/Python_For_SEO/2_bulk_csv_operations/data\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hackernoon.com-top-pages-by-traffic-subdomains-US-17-May-2020_20-20-38-3c2d0502092ca7b22c9527c370526f6b.csv\r\n",
      "machinelearningmastery.com-top-pages-by-traffic-subdomains-US-17-May-2020_20-25-38-b4088b6c6c987653748b10c0543a5713.csv\r\n",
      "pbpython.com-top-pages-by-traffic-subdomains-US-17-May-2020_20-24-30-2c4e06e2ea39cce8b2f514e24c929e51.csv\r\n",
      "towardsdatascience.com-top-pages-by-traffic-subdomains-US-17-May-2020_20-15-48-03e00fb8d3976a642dd2db330422cef7.csv\r\n",
      "www.datacamp.com-top-pages-by-traffic-subdomains-US-17-May-2020_20-21-48-821c6875ceb05705bce7e0a5a032d622.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Use Global To Match The Pattern '.csv'\n",
    "\n",
    "We will now match the file pattern ('.csv') within all of the files located in the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_extension = '.csv'\n",
    "all_filenames = [i for i in glob.glob(f\"*{file_extension}\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are all of the filenames ending in .csv ['hackernoon.com-top-pages-by-traffic-subdomains-US-17-May-2020_20-20-38-3c2d0502092ca7b22c9527c370526f6b.csv', 'machinelearningmastery.com-top-pages-by-traffic-subdomains-US-17-May-2020_20-25-38-b4088b6c6c987653748b10c0543a5713.csv', 'pbpython.com-top-pages-by-traffic-subdomains-US-17-May-2020_20-24-30-2c4e06e2ea39cce8b2f514e24c929e51.csv', 'towardsdatascience.com-top-pages-by-traffic-subdomains-US-17-May-2020_20-15-48-03e00fb8d3976a642dd2db330422cef7.csv', 'www.datacamp.com-top-pages-by-traffic-subdomains-US-17-May-2020_20-21-48-821c6875ceb05705bce7e0a5a032d622.csv'].\n"
     ]
    }
   ],
   "source": [
    "print(f\"These are all of the filenames ending in .csv {all_filenames}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Let's Combine All Of The Files Within The List And Export As A CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below we will read all of the csv's and will then use the pd.concat() method to stack every dataframe one on top of another. \n",
    "\n",
    "But before we do that, let's make sure that we can get one result within a dataframe by adding the appropriate encoding: \n",
    "\n",
    "- UTF-16 (This is a specific encoding type)\n",
    "- \\t (tab delimited data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hackernoon.com-top-pages-by-traffic-subdomains-US-17-May-2020_20-20-38-3c2d0502092ca7b22c9527c370526f6b.csv'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hackernoon.com-top-pages-by-traffic-subdomains-US-17-May-2020_20-20-38-3c2d0502092ca7b22c9527c370526f6b.csv',\n",
    "           delimiter='\\t', encoding='UTF-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(267, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv_data = pd.concat([pd.read_csv(f, delimiter='\\t', encoding='UTF-16') for f in all_filenames])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's break down what the above line of code does, firstly we loop over all of the filenames and assign them one by one to the f variable. Each csv file is then read & converted into a pandas dataframe by:\n",
    "\n",
    "~~~\n",
    "\n",
    "pd.read_csv(f, delimiter='\\t', encoding='UTF-16')\n",
    "\n",
    "~~~\n",
    "\n",
    "Then we concatenate all of the dataframes together and stack them one on top of each other using: \n",
    "\n",
    "~~~\n",
    "\n",
    "pd.concat()  # This command by default will stack dataframes vertically rather than horizontally.\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it, within 8 lines of code you're now able to easily combine as many .csv files as you want! \n",
    "\n",
    "- Remember that all of the csv files <strong> must have the same columns otherwise you will not be able to effectively concatenate them! </strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 Save Your New DataFrame To CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use the <strong> os.chdir('..') </strong> to go up one working directory before saving our data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jamesphoenix/Desktop/Imran_And_James_Projects/Python_For_SEO/2_bulk_csv_operations\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mdata\u001b[m\u001b[m\r\n",
      "how-to-combine-multiple-csv-files-in-python.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv_data.to_csv('combined_csv_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
